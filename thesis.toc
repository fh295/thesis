\thispagestyle {empty}
\contentsline {chapter}{\numberline {1}Introduction}{13}{chapter.1}
\contentsline {chapter}{\numberline {2}Understanding and evaluating models of word representation}{15}{chapter.2}
\contentsline {paragraph}{The Challenge of Evaluation}{16}{section*.5}
\contentsline {section}{\numberline {2.1}Reproducing human semantic knowledge}{17}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Similarity and Association}{18}{subsection.2.1.1}
\contentsline {paragraph}{Association and similarity in NLP}{19}{section*.7}
\contentsline {section}{\numberline {2.2}Motivation for SimLex-999}{20}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Concepts, part-of-speech and concreteness}{21}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Existing gold standards and evaluation resources}{21}{subsection.2.2.2}
\contentsline {paragraph}{Representative}{21}{section*.8}
\contentsline {paragraph}{Clearly-defined}{21}{section*.9}
\contentsline {paragraph}{Consistent and reliable}{22}{section*.10}
\contentsline {paragraph}{}{22}{section*.11}
\contentsline {paragraph}{\bf WordSim-353}{22}{section*.12}
\contentsline {paragraph}{\bf WS-Sim}{23}{section*.13}
\contentsline {paragraph}{\bf Rubenstein \& Goodenough}{24}{section*.14}
\contentsline {paragraph}{\bf The MEN Test Collection}{24}{section*.15}
\contentsline {paragraph}{\bf Synonym detection sets}{24}{section*.16}
\contentsline {section}{\numberline {2.3}The SimLex-999 Dataset}{25}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Choice of Concepts}{25}{subsection.2.3.1}
\contentsline {paragraph}{Separating similarity from association}{25}{section*.17}
\contentsline {paragraph}{POS category}{25}{section*.18}
\contentsline {paragraph}{Concreteness}{26}{section*.19}
\contentsline {paragraph}{Final sampling}{27}{section*.21}
\contentsline {subsection}{\numberline {2.3.2}Question Design}{27}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Context-free rating}{29}{subsection.2.3.3}
\contentsline {subsection}{\numberline {2.3.4}Questionnaire structure}{30}{subsection.2.3.4}
\contentsline {subsection}{\numberline {2.3.5}Participants}{30}{subsection.2.3.5}
\contentsline {subsection}{\numberline {2.3.6}Post-processing}{31}{subsection.2.3.6}
\contentsline {section}{\numberline {2.4}Analysis of Dataset}{31}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Inter-annotator agreement}{32}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}Response validity: Similarity not association}{33}{subsection.2.4.2}
\contentsline {subsection}{\numberline {2.4.3}Finer-grained Semantic Relations}{34}{subsection.2.4.3}
\contentsline {section}{\numberline {2.5}Evaluating Models with SimLex-999}{37}{section.2.5}
\contentsline {subsection}{\numberline {2.5.1}Neural language models for word representation}{37}{subsection.2.5.1}
\contentsline {paragraph}{\bf Collobert \& Weston}{37}{section*.28}
\contentsline {paragraph}{\bf Huang et al.}{38}{section*.29}
\contentsline {paragraph}{\bf Log-linear models}{38}{section*.30}
\contentsline {subsection}{\numberline {2.5.2}\bf Vector space (counting) models}{40}{subsection.2.5.2}
\contentsline {paragraph}{\bf LSA}{40}{section*.31}
\contentsline {subsection}{\numberline {2.5.3}Results}{40}{subsection.2.5.3}
\contentsline {paragraph}{\bf Overall performance on SimLex-999}{41}{figure.caption.34}
\contentsline {paragraph}{\bf Modeling similarity vs. association}{42}{section*.35}
\contentsline {paragraph}{\bf Learning concepts of different POS}{43}{section*.39}
\contentsline {paragraph}{\bf Learning concrete and abstract concepts}{45}{figure.caption.41}
\contentsline {section}{\numberline {2.6}Conclusion}{46}{section.2.6}
\contentsline {paragraph}{What is so special about neural word embeddings?}{47}{section*.42}
\contentsline {paragraph}{The future of word representations}{48}{section*.43}
\contentsline {chapter}{\numberline {3}Learning word representations from more than text}{51}{chapter.3}
\contentsline {section}{\numberline {3.1}Grounded acquisition of abstract concepts from multi-modal data}{52}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Model Design}{54}{subsection.3.1.1}
\contentsline {paragraph}{Language-only model}{54}{section*.44}
\contentsline {subsection}{\numberline {3.1.2}Information sources}{55}{subsection.3.1.2}
\contentsline {paragraph}{ESPGame dataset}{55}{section*.46}
\contentsline {paragraph}{CSLB Property Norms}{56}{section*.47}
\contentsline {paragraph}{Linguistic input}{56}{section*.48}
\contentsline {subsection}{\numberline {3.1.3}Evaluation}{56}{subsection.3.1.3}
\contentsline {subsection}{\numberline {3.1.4}Results and Discussion}{58}{subsection.3.1.4}
\contentsline {subsection}{\numberline {3.1.5}Combining information sources}{58}{subsection.3.1.5}
\contentsline {subsection}{\numberline {3.1.6}Propagating input to abstract concepts}{59}{subsection.3.1.6}
\contentsline {paragraph}{Johns and Jones}{59}{section*.52}
\contentsline {paragraph}{Ridge Regression}{60}{section*.53}
\contentsline {paragraph}{Comparisons}{60}{section*.54}
\contentsline {subsection}{\numberline {3.1.7}Direct representation vs. propagation}{62}{subsection.3.1.7}
\contentsline {subsection}{\numberline {3.1.8}Source and quantity of perceptual input}{63}{subsection.3.1.8}
\contentsline {subsection}{\numberline {3.1.9}Conclusions}{64}{subsection.3.1.9}
\contentsline {paragraph}{Type I}{64}{section*.57}
\contentsline {paragraph}{Type II}{64}{section*.58}
\contentsline {paragraph}{Type III}{65}{section*.59}
\contentsline {section}{\numberline {3.2}Learning word representations from bilingual data using encoder-decoder models}{65}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Neural Machine Translation Models}{66}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Other bilingual models of learning word representations}{66}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Experiments}{67}{subsection.3.2.3}
\contentsline {subsubsection}{\numberline {3.2.3.1}Similarity and relatedness modelling}{68}{subsubsection.3.2.3.1}
\contentsline {subsubsection}{\numberline {3.2.3.2}Importance of training data quantity}{71}{subsubsection.3.2.3.2}
\contentsline {subsubsection}{\numberline {3.2.3.3}Analogy resolution}{72}{subsubsection.3.2.3.3}
\contentsline {section}{\numberline {3.3}Effect of Target Language}{73}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Overcoming the vocabulary size problem}{74}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}How similarity emerges in NMT embeddings}{76}{subsection.3.3.2}
\contentsline {subsection}{\numberline {3.3.3}Conclusions}{77}{subsection.3.3.3}
\contentsline {section}{\numberline {3.4}Discussion}{78}{section.3.4}
\contentsline {chapter}{\numberline {4}Representing phrases with neural language models}{81}{chapter.4}
\contentsline {section}{\numberline {4.1}Neural language model architectures}{83}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Long short-term memory}{84}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Bag-of-words NLMs}{85}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Pre-trained input representations}{86}{subsection.4.1.3}
\contentsline {subsection}{\numberline {4.1.4}Training objective}{86}{subsection.4.1.4}
\contentsline {subsection}{\numberline {4.1.5}Implementation details}{86}{subsection.4.1.5}
\contentsline {section}{\numberline {4.2}Reverse dictionaries}{87}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Data collection and training}{88}{subsection.4.2.1}
\contentsline {subsection}{\numberline {4.2.2}Comparisons}{89}{subsection.4.2.2}
\contentsline {subsection}{\numberline {4.2.3}Reverse dictionary evaluation}{90}{subsection.4.2.3}
\contentsline {subsection}{\numberline {4.2.4}Results}{91}{subsection.4.2.4}
\contentsline {subsection}{\numberline {4.2.5}Qualitative analysis}{93}{subsection.4.2.5}
\contentsline {subsection}{\numberline {4.2.6}Cross-lingual reverse dictionaries}{94}{subsection.4.2.6}
\contentsline {subsection}{\numberline {4.2.7}Discussion}{95}{subsection.4.2.7}
\contentsline {section}{\numberline {4.3}Answering crossword questions}{96}{section.4.3}
\contentsline {subsection}{\numberline {4.3.1}Evaluation}{96}{subsection.4.3.1}
\contentsline {subsection}{\numberline {4.3.2}Benchmarks and comparisons}{97}{subsection.4.3.2}
\contentsline {subsection}{\numberline {4.3.3}Results}{98}{subsection.4.3.3}
\contentsline {subsection}{\numberline {4.3.4}Qualitative analysis}{100}{subsection.4.3.4}
\contentsline {section}{\numberline {4.4}Conclusion}{101}{section.4.4}
\contentsline {chapter}{\numberline {5}Representing sentences with neural language models}{103}{chapter.5}
\contentsline {section}{\numberline {5.1}Distributed Sentence Representations}{104}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Existing Models Trained on Text}{105}{subsection.5.1.1}
\contentsline {subsection}{\numberline {5.1.2}Models Trained on Structured Resources}{106}{subsection.5.1.2}
\contentsline {subsection}{\numberline {5.1.3}Novel Text-Based Models}{107}{subsection.5.1.3}
\contentsline {subsection}{\numberline {5.1.4}Training and Model Selection}{108}{subsection.5.1.4}
\contentsline {section}{\numberline {5.2}Evaluating Sentence Representations}{109}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Supervised Evaluations}{110}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Unsupervised Evaluations}{111}{subsection.5.2.2}
\contentsline {section}{\numberline {5.3}Results}{112}{section.5.3}
\contentsline {section}{\numberline {5.4}Discussion}{112}{section.5.4}
\contentsline {section}{\numberline {5.5}Conclusion}{116}{section.5.5}
\contentsline {chapter}{\numberline {6}Representing semantics in memory networks}{119}{chapter.6}
\contentsline {chapter}{\numberline {7}Conclusion}{121}{chapter.7}
\contentsline {chapter}{Bibliography}{123}{section*.80}
\contentsline {chapter}{\numberline {A}Extra Information}{141}{appendix.A}
