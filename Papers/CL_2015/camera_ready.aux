\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{finkelstein2001placing}
\citation{bruni2012distributional}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.0.1}}
\citation{budanitsky2006evaluating,agirre2009study}
\citation{hatzivassiloglou2001simfinder}
\citation{turney2012domain}
\citation{tversky1977features}
\citation{cimiano2005learning,biemann2005ontology,li2006exploring}
\citation{he2008indirect,marton2009improved}
\citation{collobert:2008,baroni2010distributional}
\citation{huang2012improving}
\citation{reisinger2010multi}
\citation{medelyan2009mining,li2014obtaining}
\citation{rubenstein1965contextual}
\citation{agirre2009study}
\citation{yong1999case,cunningham2005information,resnik201011}
\citation{gentner1978relational}
\citation{hill2013quantitative}
\citation{huang2012improving}
\citation{collobert:2008}
\citation{mikolov2013efficient}
\citation{turney2010frequency}
\citation{landauer1997solution}
\citation{agirre2009study,levy2014dependency}
\citation{agirre2009study,kiela2014systematic}
\@writefile{toc}{\contentsline {section}{\numberline {2}Design Motivation}{3}{section.0.2}}
\citation{plaut1995semantic,mcrae2012semantic}
\citation{mcrae2012semantic}
\citation{fellbaum1999wordnet}
\citation{wu1994verbs}
\citation{wu1994verbs}
\citation{nelson2004university}
\citation{he2008indirect,Haghighi2008Learning,marton2009improved,beltagysemantic}
\citation{navigli2009word}
\citation{phan2008learning}
\citation{rose2002reuters}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Similarity and Association}{4}{subsection.0.2.1}}
\citation{huang2012improving,reisinger2010multi,luong2013better}
\citation{budanitsky2006evaluating}
\citation{turney2012domain}
\citation{agirre2009study}
\citation{agirre2009study}
\citation{andrews2009integrating,kiela2014systematic,levy2014dependency}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Top: Concept pairs with the lowest WupSim scores in the USF dataset overall. Bottom: Pairs with the largest discrepancy in rank between association strength (high) and WupSim (low).}}{5}{table.0.1}}
\newlabel{font-table}{{1}{5}{Top: Concept pairs with the lowest WupSim scores in the USF dataset overall. Bottom: Pairs with the largest discrepancy in rank between association strength (high) and WupSim (low)}{table.0.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Association and similarity in NLP}{5}{subsubsection.0.2.1.1}}
\citation{agirre2009study,levy2014dependency}
\citation{agirre2009study,kiela2014systematic}
\citation{gentner2006verbs}
\citation{markman1997similar}
\citation{hill2014multi}
\citation{paivio1991dual,hill2013quantitative}
\citation{hill2013concreteness}
\citation{kielaimproving}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Concepts, part-of-speech and concreteness}{6}{subsection.0.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Existing gold standards and evaluation resources}{6}{subsection.0.2.3}}
\@writefile{toc}{\contentsline {paragraph}{Representative}{6}{section*.1}}
\@writefile{toc}{\contentsline {paragraph}{Clearly-defined}{6}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Consistent and reliable}{6}{section*.3}}
\citation{finkelstein2001placing}
\citation{huang2012improving,bansal2014tailoring}
\citation{collobert:2008}
\citation{huang2012improving}
\citation{huang2012improving}
\citation{pado2007flexible,reisinger2010mixture,silberer2014learning}
\citation{yong1999case,cunningham2005information,resnik201011}
\citation{alfonseca2002extending}
\citation{agirre2009study}
\@writefile{toc}{\contentsline {paragraph}{}{7}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{\bf  WordSim-353}{7}{section*.5}}
\@writefile{toc}{\contentsline {paragraph}{\bf  WS-Sim}{7}{section*.6}}
\citation{agirre2009study}
\citation{agirre2009study}
\citation{hassan2011semantic}
\citation{rubenstein1965contextual}
\citation{bruni2012distributional}
\citation{bruni2012distributional2,bernardi2013relatedness}
\citation{bruni2012distributional}
\citation{landauer1997solution}
\citation{griffiths2007topics}
\citation{turney2010frequency}
\@writefile{toc}{\contentsline {paragraph}{\bf  Rubenstein \& Goodenough}{8}{section*.7}}
\@writefile{toc}{\contentsline {paragraph}{\bf  The MEN Test Collection}{8}{section*.8}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Synonym detection sets}{8}{section*.9}}
\citation{leech1994claws4}
\citation{fellbaum1999wordnet}
\citation{hill2014multi,kielaimproving}
\@writefile{toc}{\contentsline {section}{\numberline {3}The SimLex-999 Dataset}{9}{section.0.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Choice of Concepts}{9}{subsection.0.3.1}}
\@writefile{toc}{\contentsline {paragraph}{Separating similarity from association}{9}{section*.10}}
\@writefile{toc}{\contentsline {paragraph}{POS category}{9}{section*.11}}
\@writefile{toc}{\contentsline {paragraph}{Concreteness}{10}{section*.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Boxplots showing the interaction between concreteness and POS for concepts in USF. The white boxes range from the first to third quartiles and the central vertical line indicates the median.}}{10}{figure.0.1}}
\@writefile{toc}{\contentsline {paragraph}{Final sampling}{10}{section*.13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Question Design}{11}{subsection.0.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Instructions for SimLex-999 annotators.}}{11}{figure.0.2}}
\citation{huang2012improving}
\citation{resnik1995using,pedersen2004wordnet}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Context-free rating}{12}{subsection.0.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A group of noun pairs to be rated by moving the sliders. The rating slider was initially at position 0, and it was possible to attribute a rating of 0, although it was necessary to have actively moved the slider to that position to proceed to the next page.}}{12}{figure.0.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Questionnaire structure}{12}{subsection.0.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Participants}{13}{subsection.0.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Post-processing}{13}{subsection.0.3.6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Analysis of Dataset}{13}{section.0.4}}
\citation{pado2007flexible,reisinger2010mixture,silberer2014learning}
\citation{bruni2012distributional2}
\citation{paivio1991dual}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Inter-annotator agreement}{14}{subsection.0.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces {\bf  Left:} Inter-annotator agreement, measured by average pairwise Spearman \relax $\rho \relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.} correlation, for ratings of concept types in SimLex-999. {\bf  Right:} Response consistency, reflecting the standard deviation of annotator ratings for each pair, averaged over all pairs in the concept category.}}{14}{figure.0.4}}
\citation{williams2009predicting}
\citation{wiebe2000learning}
\citation{agirre2009study}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  {\bf  Top: Similarity aligns with association} Pairs with a small difference in rank between USF (association) and SimLex-999 (similarity) scores for each POS category. {\bf  Bottom: Similarity contrasts with association} Pairs with a high difference in rank for each POS category. *Note that the distribution of USF association scores on the interval [0,10] is highly skewed towards the lower bound in both SimLex-999 and the USF dataset as a whole.}}{15}{table.0.2}}
\newlabel{font-table}{{2}{15}{{\bf Top: Similarity aligns with association} Pairs with a small difference in rank between USF (association) and SimLex-999 (similarity) scores for each POS category. {\bf Bottom: Similarity contrasts with association} Pairs with a high difference in rank for each POS category. *Note that the distribution of USF association scores on the interval [0,10] is highly skewed towards the lower bound in both SimLex-999 and the USF dataset as a whole}{table.0.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Response validity: Similarity not association}{15}{subsection.0.4.2}}
\citation{cruse1986lexical}
\citation{levysupervised}
\citation{rosch1976structural}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces {\bf  (a)} Pairs rated by WS-353 annotators (blue points, ranked by rating) and the corresponding rating of annotators following the SimLex-999 instructions (red points). {\bf  (b-c)} The same analysis, restricted to pairs in the WS-Sim or WS-Rel subsets of WS-353.}}{16}{figure.0.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Finer-grained Semantic Relations}{16}{subsection.0.4.3}}
\citation{baroni2014don}
\citation{bengio2003}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average SimLex and USF free association scores across pairs representing different fine-grained semantic relations. All relations were extracted from WordNet. \relax $n\_hypernym\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.} refers to a direct hypernymy path of length \relax $n\relax \GenericError  {               }{LaTeX Error: Bad math environment delimiter}{See the LaTeX manual or LaTeX Companion for explanation.}{Your command was ignored.\MessageBreak Type  I <command> <return>  to replace it with another command,\MessageBreak or  <return>  to continue without it.}. Note that the average SimLex rating across all 999 word pairs (dashed red line) is much higher than the average USF rating (dashed golden line) because of differences in the rating procedure. The more interesting differences concern the relative strength of similarity vs. association across the different relation types.}}{17}{figure.0.6}}
\citation{collobert:2008}
\citation{turian2010word}
\citation{collobert:2008}
\citation{lewis2004rcv1}
\citation{huang2012improving}
\citation{collobert:2008}
\citation{collobert:2008}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluating Models with SimLex-999}{18}{section.0.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Semantic models}{18}{subsection.0.5.1}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Collobert \& Weston}{18}{section*.14}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Huang et al.}{18}{section*.15}}
\citation{mikolov2013efficient}
\citation{mikolov2013efficient,mikolov2013distributed}
\@writefile{toc}{\contentsline {paragraph}{\bf  Mikolov et al.}{19}{section*.16}}
\citation{kiela2014systematic}
\citation{bird2006nltk}
\citation{recchia2009more}
\citation{landauer1997solution}
\citation{golub1970singular}
\citation{mikolov2013efficient}
\citation{huang2012improving}
\citation{collobert:2008}
\citation{lewis2004rcv1}
\citation{huang2012improving}
\citation{huang2012improving}
\citation{huang2012improving}
\citation{huang2012improving}
\citation{collobert:2008}
\citation{mikolov2013efficient}
\citation{mikolov2013efficient}
\citation{lewis2004rcv1}
\citation{baroni2014don}
\@writefile{toc}{\contentsline {paragraph}{\bf  Vector Space Model (VSM)}{20}{section*.17}}
\@writefile{toc}{\contentsline {paragraph}{\bf  SVD}{20}{section*.18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results}{20}{subsection.0.5.2}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Overall performance on SimLex-999}{20}{figure.0.8}}
\citation{huang2012improving}
\citation{collobert:2008}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Performance of NLMs on WS-353, MEN and SimLex-999. All models are trained on Wikipedia; note that as Wikipedia is constantly growing, the \namecite {mikolov2013efficient} model exploited slightly more training data ($\approx $1000m tokens) than the \namecite {huang2012improving} model ($\approx $990m), which in turn exploited more than the \namecite {collobert:2008} model ($\approx $852m). Dashed horizontal lines indicate the level of inter-annotator agreement for the three datasets.}}{21}{figure.0.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Comparison between the leading NLM, \emph  {Mikolov et al.}, the vector space model, \emph  {VSM}, and the \emph  {SVD} model. All models were trained on the $\approx $150m word RCV1 Corpus \cite {lewis2004rcv1}.}}{21}{figure.0.8}}
\citation{collobert:2008}
\citation{huang2012improving}
\citation{mikolov2013efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The ability of NLMs to model the similarity of highly-associated concepts versus concepts in general. The two models on the right hand side also demonstrate the effect of training an NLM (the \namecite {mikolov2013efficient} model) on running-text (\emph  {Mikolov et al.}) vs. on dependency-based input (\emph  {Levy \& Goldberg}).}}{22}{figure.0.9}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Modeling similarity vs. association}{22}{section*.20}}
\citation{levy2014dependency}
\citation{mikolov2013efficient}
\citation{}
\citation{mikolov2013efficient}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The effect of different window sizes (indicated in square brackets [ ]) on NLM and SVD models. }}{23}{figure.0.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Performance of models on POS-based subsets of SimLex-999. The window size for each model is indicated in parentheses. Inter-annotator agreement for each POS is indicated by the dashed horizontal line.}}{23}{figure.0.11}}
\citation{levy2014dependency}
\citation{mikolov2013efficient}
\citation{markman1997similar}
\citation{sun2008verb}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The importance of dependency-focussed contexts (in the Levy \& Goldberg model) for capturing concepts of different POS, when compared to a standard Skipgram (BOW) model trained on the same Wikipedia corpus.}}{24}{figure.0.12}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Learning concepts of different POS}{24}{section*.21}}
\@writefile{toc}{\contentsline {paragraph}{\bf  Learning concrete and abstract concepts}{24}{figure.0.13}}
\citation{hill2013concreteness}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Performance of models on concreteness-based subsets of SimLex-999. Window size is indicated in parentheses. Horizontal dashed lines indicate inter-annotator agreement between SimLex-999 annotators on the two subsets.}}{25}{figure.0.13}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{25}{section.0.6}}
\citation{gershmanmetaphor}
\citation{barsalou2003grounding}
\citation{firth1957papers}
\bibstyle{fullname}
\bibdata{simlex}
\bibcite{agirre2009study}{\citename {Agirre \bgroup et al.\egroup }2009}
\bibcite{alfonseca2002extending}{\citename {Alfonseca and Manandhar}2002}
\bibcite{andrews2009integrating}{\citename {Andrews, Vigliocco, and Vinson}2009}
\bibcite{bansal2014tailoring}{\citename {Bansal, Gimpel, and Livescu}2014}
\bibcite{baroni2014don}{\citename {Baroni, Dinu, and Kruszewski}2014}
\bibcite{baroni2010distributional}{\citename {Baroni and Lenci}2010}
\bibcite{barsalou2003grounding}{\citename {Barsalou \bgroup et al.\egroup }2003}
\bibcite{beltagysemantic}{\citename {Beltagy, Erk, and Mooney}2014}
\bibcite{bengio2003}{\citename {Bengio \bgroup et al.\egroup }2003}
\bibcite{bernardi2013relatedness}{\citename {Bernardi \bgroup et al.\egroup }2013}
\bibcite{biemann2005ontology}{\citename {Biemann}2005}
\bibcite{bird2006nltk}{\citename {Bird}2006}
\bibcite{bruni2012distributional}{\citename {Bruni \bgroup et al.\egroup }2012a}
\bibcite{bruni2012distributional2}{\citename {Bruni \bgroup et al.\egroup }2012b}
\bibcite{budanitsky2006evaluating}{\citename {Budanitsky and Hirst}2006}
\bibcite{cimiano2005learning}{\citename {Cimiano, Hotho, and Staab}2005}
\bibcite{collobert:2008}{\citename {Collobert and Weston}2008}
\bibcite{cruse1986lexical}{\citename {Cruse}1986}
\bibcite{cunningham2005information}{\citename {Cunningham}2005}
\bibcite{fellbaum1999wordnet}{\citename {Fellbaum}1998}
\bibcite{finkelstein2001placing}{\citename {Finkelstein \bgroup et al.\egroup }2001}
\bibcite{firth1957papers}{\citename {Firth}1957}
\bibcite{gentner1978relational}{\citename {Gentner}1978}
\bibcite{gentner2006verbs}{\citename {Gentner}2006}
\bibcite{gershmanmetaphor}{\citename {Gershman and Dyer}2014}
\bibcite{golub1970singular}{\citename {Golub and Reinsch}1970}
\bibcite{griffiths2007topics}{\citename {Griffiths, Steyvers, and Tenenbaum}2007}
\bibcite{Haghighi2008Learning}{\citename {Haghighi \bgroup et al.\egroup }2008}
\bibcite{hassan2011semantic}{\citename {Hassan and Mihalcea}2011}
\bibcite{hatzivassiloglou2001simfinder}{\citename {Hatzivassiloglou \bgroup et al.\egroup }2001}
\bibcite{he2008indirect}{\citename {He \bgroup et al.\egroup }2008}
\bibcite{hill2013concreteness}{\citename {Hill, Kiela, and Korhonen}2013}
\bibcite{hill2013quantitative}{\citename {Hill, Korhonen, and Bentz}2013}
\bibcite{hill2014multi}{\citename {Hill, Reichart, and Korhonen}2014}
\bibcite{huang2012improving}{\citename {Huang \bgroup et al.\egroup }2012}
\bibcite{kiela2014systematic}{\citename {Kiela and Clark}2014}
\bibcite{kielaimproving}{\citename {Kiela \bgroup et al.\egroup }2014}
\bibcite{landauer1997solution}{\citename {Landauer and Dumais}1997}
\bibcite{leech1994claws4}{\citename {Leech, Garside, and Bryant}1994}
\bibcite{levy2014dependency}{\citename {Levy and Goldberg}2014}
\bibcite{levysupervised}{\citename {Levy \bgroup et al.\egroup }2015}
\bibcite{lewis2004rcv1}{\citename {Lewis \bgroup et al.\egroup }2004}
\bibcite{li2014obtaining}{\citename {Li \bgroup et al.\egroup }2014}
\bibcite{li2006exploring}{\citename {Li \bgroup et al.\egroup }2006}
\bibcite{luong2013better}{\citename {Luong, Socher, and Manning}2013}
\bibcite{markman1997similar}{\citename {Markman and Wisniewski}1997}
\bibcite{marton2009improved}{\citename {Marton, Callison-Burch, and Resnik}2009}
\bibcite{mcrae2012semantic}{\citename {McRae, Khalkhali, and Hare}2012}
\bibcite{medelyan2009mining}{\citename {Medelyan \bgroup et al.\egroup }2009}
\bibcite{mikolov2013efficient}{\citename {Mikolov \bgroup et al.\egroup }2013a}
\bibcite{mikolov2013distributed}{\citename {Mikolov \bgroup et al.\egroup }2013b}
\bibcite{navigli2009word}{\citename {Navigli}2009}
\bibcite{nelson2004university}{\citename {Nelson, McEvoy, and Schreiber}2004}
\bibcite{pado2007flexible}{\citename {Pad\'o, Pad\'o, and Erk}2007}
\bibcite{paivio1991dual}{\citename {Paivio}1991}
\bibcite{pedersen2004wordnet}{\citename {Pedersen, Patwardhan, and Michelizzi}2004}
\bibcite{phan2008learning}{\citename {Phan, Nguyen, and Horiguchi}2008}
\bibcite{plaut1995semantic}{\citename {Plaut}1995}
\bibcite{recchia2009more}{\citename {Recchia and Jones}2009}
\bibcite{reisinger2010mixture}{\citename {Reisinger and Mooney}2010a}
\bibcite{reisinger2010multi}{\citename {Reisinger and Mooney}2010b}
\bibcite{resnik1995using}{\citename {Resnik}1995}
\bibcite{resnik201011}{\citename {Resnik and Lin}2010}
\bibcite{rosch1976structural}{\citename {Rosch, Simpson, and Miller}1976}
\bibcite{rose2002reuters}{\citename {Rose, Stevenson, and Whitehead}2002}
\bibcite{rubenstein1965contextual}{\citename {Rubenstein and Goodenough}1965}
\bibcite{silberer2014learning}{\citename {Silberer and Lapata}2014}
\bibcite{sun2008verb}{\citename {Sun, Korhonen, and Krymolowski}2008}
\bibcite{turian2010word}{\citename {Turian, Ratinov, and Bengio}2010}
\bibcite{turney2012domain}{\citename {Turney}2012}
\bibcite{turney2010frequency}{\citename {Turney and Pantel}2010}
\bibcite{tversky1977features}{\citename {Tversky}1977}
\bibcite{wiebe2000learning}{\citename {Wiebe}2000}
\bibcite{williams2009predicting}{\citename {Williams and Anand}2009}
\bibcite{wu1994verbs}{\citename {Wu and Palmer}1994}
\bibcite{yong1999case}{\citename {Yong and Foo}1999}
\questionmark{}
