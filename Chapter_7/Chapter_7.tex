% This chapter is the conclusion

Computational models that encode semantic knowledge in distributed representations are performing better and better on tasks that mirror human cognitive capacities. However, unlike these models, which are each trained to accomplish a specific AI task, humans are continuously learning without a particular skill or application in mind. The human learner is able to acquire general concepts and knowledge from experience via constant observation of the environment, such that it can later be applied quickly and effectively to multiple tasks and goals. The objective of this thesis has been to develop ways of effecting this human-like unsupervised learning in neural language models.

Thanks largely to the power of the distributional hypothesis of natural language, various established methods already existed for acquiring general-purpose word representations from linguistic input. For phrase or sentence semantics, however, this was not the case. Most general approaches to interpreting phrases or sentences involved mapping between text and symbolic or localist representations such as logical forms (see e.g.~\citealt{poon2009unsupervised}). This thesis demonstrates that, in light of recently-developed neural language modelling architectures, the symbolic approach is no longer the only way to represent phrases and sentences in a generally-applicable way. In the long term, the potential impact of extending the distributional approach from words to phrases and sentences is tremendous, given the desirable computational and modelling properties of distributed representations and the fact that that most information transfer between humans involves these larger units rather than words in isolation. 

\section{Contributions of this thesis}

\paragraph{A new resource for the evaluation of distributed word representations} A clear understanding of how word concepts can be acquired from text can ultimately shed light on the same phenomenon in the case of larger linguistic units. However, without robust ways to evaluate the quality of word representations, it would be difficult to compare various approaches and detect improvements. Existing methods suffered from a range of limitations, such as low word coverage, poorly defined scores or low inter-rater agreement. In Chapter~\ref{CH2} I described SimLex-999, a resource designed to mitigate these limitations. SimLex covers a more representative set of word concepts than many alternative evaluation resources. It measures semantic similarity, a relation about which native English speakers seem to have clearer, more consistent intuitions. Since its release, SimLex-999 has been used to evaluate numerous new algorithms and approaches for word representation learning (see e.g.~\citealt{lazaridou2015combining,levy2015improving,lu2015deep}). It has also been translated into German, Italian and Russian~\citep{leviant2016separated}. 

\paragraph{A novel method for acquiring distributed word representations from bilingual texts} The fact that SimLex-999 facilitates a better understanding of the differing representational geometry of word embedding spaces was underlined in Chapter~\ref{CH3}. Here, I showed how the objective of translating between sentences in bilingual corpora, via neural machine translation models, yields word representation spaces that are qualitatively different from those learned via more conventional monolingual methods. Specifically, neural translation embeddings are more naturally orientated according to semantic similarity than conventional word embeddings. This observations enabled us to achieve what was at the time the best reported performance of a distributional model on SimLex-999.  

\paragraph{A simple method for extending word representations to phrases} In Chapter~\ref{CH4}, I showed how NLMs could be trained effectively on the textual definitions or descriptions in dictionaries and encyclopedias. In these models, dictionaries provide a bridge between lexical meaning and phrase meaning, allowing the model's interpretation of phrases to be `supervised' by the corresponding lexical representation (acquired by models like those described in Chapters~\ref{CH2} and~\ref{CH3}). The combination of the representational power of NLMs and the principled semantic information in dictionaries proved to be very powerful. The trained models generalise well beyond the training data. They are capable of beating established dictionary-indexing software at retrieving concepts not defined in the training data, an effect that is magnified when the linguistic style of description of definition differs from that of the training set, and can even answer general-knowledge crossword questions. Moreover, a systematic comparison of various methods for acquiring phrase or sentence representations from unlabelled data (Chapter~\ref{CH5}) revealed the representations encoded by models trained in this way to perform more consistently than alternative NLM architectures across a suite of supervised and unsupervised evaluations. 

\paragraph{Two novel models for learning distributed sentence representations from text} In Chapter~\ref{CH5}, I also developed two further algorithms for acquiring distributed sentence representations, each with certain specific advantages over alternative approaches. The first, the sequential denoising autoencoder, can be trained on any collection of unordered sentences, and learns representations that are particularly applicable to paraphrasing applications. The second, FastSent, is a modification CBOW, a well-known log-linear model for lexical representation learning, in which word embeddings are optimised to form useful sentence representations under the addition operation. Like other shallow neural language models, FastSent performs best in unsupervised applications involving a linear decoding of its representation space. It outperforms alternatives at direct prediction of sentence relatedness, and qualitative analysis (e.g. via the web demo) suggests a more semantically plausible space of sentence representations than alternatives.       

\paragraph{Interpreting language in context with memory networks} Much like words, sentences are rarely interpreted in isolation, but as elements in some wider story, discourse or conversation. In Chapter~\ref{CH6}, I described how \emph{memory networks}, a novel neural network architecture, can be adapted as a context-aware model of sentence processing. The first memory networks were applied to question answering about simulated discussions, but here I applied them to natural language, and the task of interpreting a sentence in a story conditioned on explicit representations of multiple previous sentences. Using the Children's Book Test, our novel training and evaluation resource for sentence completion in context, I compared multiple ways of representing sentences in such a model. As well as a model of machine comprehension in context, the model framework and evaluation resource together provide an extrinsic (task-based) means to compare different strategies for encoding language in distributed memory. Using this strategy, I showed that models that effectively focus on small sub-sentential windows convey more useful information than those whose focus is both broader (entire sentences) or narrower (ordered sequences of words). This is one of the first studies to apply neural language models to sentence processing in context. The contributions can be understood in a general tendency of language processing research away from analysing individual sentences in isolation, towards models that can effectively interpret utterances as part of a broader stream of language.  

\section{Future work} The approaches to knowledge representation and language learning described in this thesis involve training models to make predictions from language corpora or structured text-based resources. The extension of the training environment beyond unstructured running text, in Chapters~\ref{CH4} and~\ref{CH5}, was intended to mitigate the discrepancy between the information available to human language learners and the signal from text alone. Nevertheless, there remains a clear point of difference between these approaches and human language learning that may be critical to address if models are to exhibit truly human-like linguistic behaviours. 

For the models considered in this thesis, the learning environment is \emph{passive}, in that the training information source is pre-determined before learning begins, and does not alter at any stage as a consequence of the output of the model. As such, these experiments mimic the part of language learning in which children observe adult language by listening to the conversations of others or reading. Such passive observation must be how babies learn their first words, and may well be a critical part of language learning even after they can talk. Nevertheless, once they can talk, children actively influence the nature of their future linguistic experience (e.g by moving conversations in a particular direction). In such an interactive setting, learners can infer linguistic meaning not simply by observing correct language, or even determining what in the world that language refers to, but also by noticing the reaction it provokes in others and benefitting from the communicative acts that it facilitates. Indeed, to realise more complex communicative acts such as negotiation, humans must ultimately learn to produce multiple utterances and receive multiple responses with a only a delayed indication of whether their linguistic behaviour was `correct' with respect to the goal in question. These aspects of learning, which are not part of the environments and algorithms studied in this thesis, may be critical for efficiently training models to replicate human language understanding and production in a robust way.

The next stage of this research programme is therefore to place the language models described in this thesis into more dynamic, interactive and goal-driven learning environments. In recent work, interactive learning frameworks such as reinforcement learning have proved very effective tools for training agents to resolve computer games, particularly when deep neural networks are used to represent the situations faced by the agent and thus effectively reduce the search space among state-action pairs~\citep{mnih2015human}. Indeed, the same strategy has also been applied to language games, in which states are described by textual descriptions and the model agent must choose between three possible actions at each stage~\citep{narasimhan2015language}. 

A general approach to training language models as agents was recently sketched by~\cite{mikolov2015roadmap}. This framework relies on a deterministic environment programmed to reflect and describe the world, a learner agent that interacts with that environment, and a \emph{teacher} agent which interacts with the learner agent in light of the environment. In a typical interaction, the teacher issues a task to the learner (\emph{find the rabbit}) and the learner has to work out how to accomplish the task by specifying a sequence of actions. Actions are communicated via language to the environment (\emph{Learner to Environment: I move left}) and the consequences of the action are communicated via language back to the leaner (\emph{Environment to Learner: You are now in the kitchen}). Aside from attempting and realising actions (\emph{Leaner to Environment: I look behind me}), the leaner might also engage the teacher to get help (\emph{Learner to Teacher: Can you remind me what to do again?}). The learner receives reward when the teacher's instructions are satisfied, and may receive penalties for undesirable behaviours such as taking too long. In principle, if learning agents have sufficient capacity for remembering, represent and generalising, they could be `taught' a general form of language understanding via exposure to multiple task/environment combinations. 

The framework of~\cite{mikolov2015roadmap}, and specifically the constraint that information about the environment is encoded in language, yields a comparatively simple way to train language models in an interactive way. Nevertheless, there are many likely challenges that must be resolved before it can be applied as a general way of yielding agents or models with robust linguistic behaviour. First, the effect of constraining all information sharing to language is not known. While language in the~\cite{mikolov2015roadmap} framework is grounded in the responses of the environment, language as a channel of information transfer is very narrow bandwidth, and the information about the consequence of actions will be much more constrained than that received by humans. Second, unlike with game-playing scenarios, linguistic behaviour (possible utterances) cannot be reduced to a (small) finite number of possible actions and corresponding symbols. On the one hand, it is not clear how the environment would learn to interpret the possibly noisy output of the learner. On the other hand, requiring the learner to generate unique, unambiguous commands would surely result in unrealistic output. Finally, there is the problem of knowing how to teach. With such a large search-space of possible utterances available to the learner, teaching an uninitiated model to find actions that are at all relevant to the environment and objective may be difficult in the general case. As the authors suggest, such a process will likely involve a structured curriculum of tasks and environments, beginning with the very simple. Even once learning is up and running, it may not be trivial to formalise the vast and dynamic selection of behavioural goals that are characteristic of human activity and which combine to make general language understanding and production viable. 

These challenges are significant, and their resolution may require expertise in many fields, from linguistics, machine-learning and neuroscience to multi-agent systems and even robotics. Nevertheless, recent developments in each of these disciplines are such that progress towards the overall goal no longer seems unattainable. And if the necessary collaborations can be realised, and progress in this direction is achieved, then for general linguistic utterances, much as is the case already for single words, the path from frequency to meaning may become a little less obscure. 
