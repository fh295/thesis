\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [0][-]{chapter.2}{Understanding and evaluating unsupervised models of word representation}{}% 2
\BOOKMARK [1][-]{subsection.2.0.1}{Comparing word representations to human conceptual space}{chapter.2}% 3
\BOOKMARK [2][-]{subsection.2.0.2}{Design motivation}{subsection.2.0.1}% 4
\BOOKMARK [3][-]{subsubsection.2.0.2.1}{Similarity and Association}{subsection.2.0.2}% 5
\BOOKMARK [3][-]{subsubsection.2.0.2.2}{Concepts, part-of-speech and concreteness}{subsection.2.0.2}% 6
\BOOKMARK [2][-]{subsection.2.0.3}{Existing gold standards and evaluation resources}{subsection.2.0.1}% 7
\BOOKMARK [1][-]{section.2.1}{The SimLex-999 Dataset}{chapter.2}% 8
\BOOKMARK [2][-]{subsection.2.1.1}{Choice of Concepts}{section.2.1}% 9
\BOOKMARK [2][-]{subsection.2.1.2}{Question Design}{section.2.1}% 10
\BOOKMARK [2][-]{subsection.2.1.3}{Context-free rating}{section.2.1}% 11
\BOOKMARK [2][-]{subsection.2.1.4}{Questionnaire structure}{section.2.1}% 12
\BOOKMARK [2][-]{subsection.2.1.5}{Participants}{section.2.1}% 13
\BOOKMARK [2][-]{subsection.2.1.6}{Post-processing}{section.2.1}% 14
\BOOKMARK [1][-]{section.2.2}{Analysis of Dataset}{chapter.2}% 15
\BOOKMARK [2][-]{subsection.2.2.1}{Inter-annotator agreement}{section.2.2}% 16
\BOOKMARK [2][-]{subsection.2.2.2}{Response validity: Similarity not association}{section.2.2}% 17
\BOOKMARK [2][-]{subsection.2.2.3}{Finer-grained Semantic Relations}{section.2.2}% 18
\BOOKMARK [1][-]{section.2.3}{Evaluating Models with SimLex-999}{chapter.2}% 19
\BOOKMARK [2][-]{subsection.2.3.1}{Semantic models}{section.2.3}% 20
\BOOKMARK [2][-]{subsection.2.3.2}{Results}{section.2.3}% 21
\BOOKMARK [1][-]{section.2.4}{Conclusion}{chapter.2}% 22
\BOOKMARK [0][-]{chapter.3}{Improved distributed word representations by learning from more than text}{}% 23
\BOOKMARK [1][-]{section.3.1}{Learning Distributed Word Representations from Text}{chapter.3}% 24
\BOOKMARK [1][-]{section.3.2}{Modelling Word Acquisition with Multi-Modal Data and Neural Language Models}{chapter.3}% 25
\BOOKMARK [2][-]{subsection.3.2.1}{Introduction}{section.3.2}% 26
\BOOKMARK [2][-]{subsection.3.2.2}{Model Design}{section.3.2}% 27
\BOOKMARK [2][-]{subsection.3.2.3}{Information Sources}{section.3.2}% 28
\BOOKMARK [2][-]{subsection.3.2.4}{Evaluation}{section.3.2}% 29
\BOOKMARK [2][-]{subsection.3.2.5}{Results and Discussion}{section.3.2}% 30
\BOOKMARK [2][-]{subsection.3.2.6}{Combining information sources}{section.3.2}% 31
\BOOKMARK [2][-]{subsection.3.2.7}{Propagating input to abstract concepts}{section.3.2}% 32
\BOOKMARK [2][-]{subsection.3.2.8}{Direct representation vs. propagation}{section.3.2}% 33
\BOOKMARK [2][-]{subsection.3.2.9}{Source and quantity of perceptual input}{section.3.2}% 34
\BOOKMARK [2][-]{subsection.3.2.10}{Conclusions}{section.3.2}% 35
\BOOKMARK [1][-]{section.3.3}{Multi-modal fusion based on image dispersion}{chapter.3}% 36
\BOOKMARK [1][-]{section.3.4}{Sequence-to-Sequence Learning of Word Representations From Bilingual Data}{chapter.3}% 37
\BOOKMARK [1][-]{section.3.5}{Learning Embeddings with Neural Language Models}{chapter.3}% 38
\BOOKMARK [2][-]{subsection.3.5.1}{Monolingual Models}{section.3.5}% 39
\BOOKMARK [2][-]{subsection.3.5.2}{Bilingual Representation-learning Models}{section.3.5}% 40
\BOOKMARK [2][-]{subsection.3.5.3}{Neural Machine Translation Models}{section.3.5}% 41
\BOOKMARK [1][-]{section.3.6}{Experiments}{chapter.3}% 42
\BOOKMARK [2][-]{subsection.3.6.1}{Similarity and relatedness modelling}{section.3.6}% 43
\BOOKMARK [2][-]{subsection.3.6.2}{Importance of training data quantity}{section.3.6}% 44
\BOOKMARK [2][-]{subsection.3.6.3}{Analogy Resolution}{section.3.6}% 45
\BOOKMARK [1][-]{section.3.7}{Effect of Target Language}{chapter.3}% 46
\BOOKMARK [1][-]{section.3.8}{Overcoming the Vocabulary Size Problem}{chapter.3}% 47
\BOOKMARK [1][-]{section.3.9}{How Similarity Emerges}{chapter.3}% 48
\BOOKMARK [1][-]{section.3.10}{Conclusion}{chapter.3}% 49
\BOOKMARK [0][-]{chapter.4}{Representing phrases with neural language models}{}% 50
\BOOKMARK [1][-]{section.4.1}{Introduction}{chapter.4}% 51
\BOOKMARK [1][-]{section.4.2}{Neural Language Model Architectures}{chapter.4}% 52
\BOOKMARK [2][-]{subsection.4.2.1}{Long Short Term Memory}{section.4.2}% 53
\BOOKMARK [2][-]{subsection.4.2.2}{Bag-of-Words NLMs}{section.4.2}% 54
\BOOKMARK [2][-]{subsection.4.2.3}{Pre-trained Input Representations}{section.4.2}% 55
\BOOKMARK [2][-]{subsection.4.2.4}{Training Objective}{section.4.2}% 56
\BOOKMARK [2][-]{subsection.4.2.5}{Implementation Details}{section.4.2}% 57
\BOOKMARK [1][-]{section.4.3}{Reverse Dictionaries}{chapter.4}% 58
\BOOKMARK [2][-]{subsection.4.3.1}{Data Collection and Training}{section.4.3}% 59
\BOOKMARK [2][-]{subsection.4.3.2}{Comparisons}{section.4.3}% 60
\BOOKMARK [2][-]{subsection.4.3.3}{Reverse Dictionary Evaluation}{section.4.3}% 61
\BOOKMARK [2][-]{subsection.4.3.4}{Results}{section.4.3}% 62
\BOOKMARK [2][-]{subsection.4.3.5}{Qualitative Analysis}{section.4.3}% 63
\BOOKMARK [2][-]{subsection.4.3.6}{Cross-Lingual Reverse Dictionaries}{section.4.3}% 64
\BOOKMARK [2][-]{subsection.4.3.7}{Discussion}{section.4.3}% 65
\BOOKMARK [1][-]{section.4.4}{General Knowledge \(crossword\) Question Answering}{chapter.4}% 66
\BOOKMARK [2][-]{subsection.4.4.1}{Evaluation}{section.4.4}% 67
\BOOKMARK [2][-]{subsection.4.4.2}{Benchmarks and Comparisons}{section.4.4}% 68
\BOOKMARK [2][-]{subsection.4.4.3}{Results}{section.4.4}% 69
\BOOKMARK [2][-]{subsection.4.4.4}{Qualitative Analysis}{section.4.4}% 70
\BOOKMARK [1][-]{section.4.5}{Conclusion}{chapter.4}% 71
\BOOKMARK [0][-]{chapter.5}{Representing sentences with neural language models}{}% 72
\BOOKMARK [1][-]{subsection.5.0.1}{Introduction}{chapter.5}% 73
\BOOKMARK [2][-]{subsection.5.0.2}{Distributed Sentence Representations}{subsection.5.0.1}% 74
\BOOKMARK [2][-]{subsection.5.0.3}{Existing Models Trained on Text}{subsection.5.0.1}% 75
\BOOKMARK [2][-]{subsection.5.0.4}{Models Trained on Structured Resources}{subsection.5.0.1}% 76
\BOOKMARK [2][-]{subsection.5.0.5}{Novel Text-Based Models}{subsection.5.0.1}% 77
\BOOKMARK [2][-]{subsection.5.0.6}{Training and Model Selection}{subsection.5.0.1}% 78
\BOOKMARK [2][-]{subsection.5.0.7}{Evaluating Sentence Representations}{subsection.5.0.1}% 79
\BOOKMARK [2][-]{subsection.5.0.8}{Supervised Evaluations}{subsection.5.0.1}% 80
\BOOKMARK [2][-]{subsection.5.0.9}{Unsupervised Evaluations}{subsection.5.0.1}% 81
\BOOKMARK [2][-]{subsection.5.0.10}{Results}{subsection.5.0.1}% 82
\BOOKMARK [2][-]{subsection.5.0.11}{Discussion}{subsection.5.0.1}% 83
\BOOKMARK [2][-]{subsection.5.0.12}{Conclusion}{subsection.5.0.1}% 84
\BOOKMARK [0][-]{chapter.6}{Representing semantics in memory networks}{}% 85
\BOOKMARK [0][-]{chapter.7}{Conclusion}{}% 86
\BOOKMARK [0][-]{section*.79}{Bibliography}{}% 87
\BOOKMARK [0][-]{appendix.A}{Extra Information}{}% 88
